services:
  deepseek-llama:
    image: ai/deepseek-r1-distill-llama:8B-Q4_K_M
    container_name: deepseek-llama
    ports:
      - "8888:8080"
    environment:
      - MODEL_PATH=/models
      - NUM_THREADS=8  # Adjust based on your hardware
      - MAX_TOKENS=4096
    volumes:
      - ./models:/models
    restart: unless-stopped
